{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** In most sessions you will be solving exercises posed in a Jupyter notebook that looks like this one. Because you are cloning a Github repository that only we can push to, you should **NEVER EDIT** any of the files you pull from Github. Instead, what you should do, is either make a new notebook and write your solutions in there, or **make a copy of this notebook and save it somewhere else** on your computer, not inside the `sds` folder that you cloned, so you can write your answers in there. If you edit the notebook you pulled from Github, those edits (possible your solutions to the exercises) may be overwritten and lost the next time you pull from Github. This is important, so don't hesitate to ask if it is unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scraping_class\n",
    "logfile = 'log.txt' ## name your log file.\n",
    "connector = scraping_class.Connector(logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercise Set 7: Parsing and Information Extraction\n",
    "\n",
    "In this Exercise Set we shall develop our webscraping skills even further by practicing **parsing** and navigating html trees using BeautifoulSoup and furthermore train extracting information from raw text with no html tags to help, using regular expressions. \n",
    "\n",
    "But just as importantly you will get a chance to think about **data quality issues** and how to ensure reliability when curating your own webdata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 7.1: Logging and data quality\n",
    "\n",
    "> **Ex. 7.1.1:** *Why is is it important to log processes in your data collection?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 7.1.1 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing your own data collection you are in charge of ensuring the quality. Many processes can go wrong, which if not spotted can lead to fundamental distortions of your dataset and in turn conclusions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.2:**\n",
    "*How does logging help with both ensuring and documenting the quality of your data?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 7.1.2 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a log allow you to spot the potential anomalies in the website you are scraping. Examples could be errors and failed calls not randomly distributed accross time or subdomains. This would prompt you to investigate the issue further. Inspecting the simple distribution of lenght of the response, can also tell you about potential artifacts in your data collection that you should look into. Maybe there are more than one template important for your parsing, or there is a certain standard response given when data is missing.\n",
    "When presenting simple statistics about the data collection, it provides transparency and signals the commitment you have made as a data curator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Section 7.2: Parsing a Table from HTML using BeautifulSoup.\n",
    "\n",
    "Yesterday I showed you a neat little prepackaged function in pandas that did all the work. However today we should learn the mechanics of it. *(It is not just for educational purposes, sometimes the package will not do exactly as you want.)*\n",
    "\n",
    "We hit the Basketball stats page from yesterday again: https://www.basketball-reference.com/leagues/NBA_2018.html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.2.1:** Here we practice simply locating the table node of interest using the `find` method build into BeautifoulSoup. But first we have to fetch the HTML using the `requests` module. Parse the tree using `BeautifulSoup`. And then use the **>Inspector<** tool (* right click on the table < press inspect element *) in your browser to see how to locate the Eastern Conference table node - i.e. the *tag* name of the node, and maybe some defining *attributes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 7.2.1 here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://www.basketball-reference.com/leagues/NBA_2018.html'\n",
    "response = connector.get(url,'table_exercise')\n",
    "html = response[0].text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "table_node = soup.find('table',attrs={'id':'confs_standings_E'}) # find table node with specific attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have located the table should now build a function that starts at a \"table node\" and parses the information, and outputs a pandas DataFrame. \n",
    "\n",
    "Inspect the element either within the notebook or through the **>Inspector<** tool and start to see how a table is written in html. Which tag names can be used to locate rows? How will you iterate through columns. Were is the header located?\n",
    "\n",
    "> **Ex. 7.1.2:** First you parse the header which can be found in the canonical tag name: thead. \n",
    "Next you use the `find_all` method to search for the tag, and iterate through each of the elements extracting the text, using the `.text` method builtin to the the node object. Store the header values in a list container. \n",
    "\n",
    "> **Ex. 7.1.3:** Next you locate the rows, using the canonical tag name: tbody. And from here you search for all rows tags. Fiugre out the tag name yourself, inspecting the tbody node in python or using the **Inspector**. \n",
    "\n",
    "> **Ex. 7.1.4:** Next run through all the rows and extract each value, similar to how you extracted the header. However here is a slight variation: Since each value node can have a different tag depending on whether it is a digit or a string, you should use the `.children` method instead of the `.find_all` - (or write compile a regex that matches both the td tag and the th tag.) \n",
    ">Once the value nodes of each row has been located using the `.children` method you should extract the value. Store the extracted rows as a list of lists: ```[[val1,val2,...valk],...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 7.2.2-4 here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eastern Conference', 'Wins', 'Losses', 'Win-Loss Percentage', 'Games Behind', 'Points Per Game', 'Opponent Points Per Game', 'Simple Rating System'] 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "name = table_node.caption.text\n",
    "\n",
    "# parse header\n",
    "header = table_node.thead.find_all('th') # locate each column name using the `th` tag, which entail a string .\n",
    "\n",
    "# extract the label you want. brevity use .text, for a more informative get teh aria-label attribute\n",
    "header = [col['aria-label'] for col in header]\n",
    "\n",
    "print(header,len(header))\n",
    "\n",
    "# parse rows: the canonical tbody locates the data body.\n",
    "body = table_node.tbody\n",
    "\n",
    "# rows are found using the \"tr\" tag\n",
    "rows = body.find_all('tr')\n",
    "\n",
    "# each row value has different tags depending on their type (digit or string)\n",
    "# function to check what tag it is and either convert to float or not. \n",
    "import numpy as np\n",
    "def convert_value_type(value_node):\n",
    "    if value_node.name == 'th':\n",
    "        return value_node.text\n",
    "    else: # assume node is td:\n",
    "        try: \n",
    "            return float(value_node.text)\n",
    "        except:\n",
    "            return np.nan # assume there is no value if it fails. \n",
    "data = []\n",
    "for row_node in rows:\n",
    "    row = []\n",
    "    for child in row_node.children:\n",
    "        row.append(convert_value_type(child))\n",
    "    data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eastern Conference</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win-Loss Percentage</th>\n",
       "      <th>Games Behind</th>\n",
       "      <th>Points Per Game</th>\n",
       "      <th>Opponent Points Per Game</th>\n",
       "      <th>Simple Rating System</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toronto Raptors*</td>\n",
       "      <td>59.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111.7</td>\n",
       "      <td>103.9</td>\n",
       "      <td>7.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston Celtics*</td>\n",
       "      <td>55.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia 76ers*</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>7.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>105.3</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cleveland Cavaliers*</td>\n",
       "      <td>50.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>9.0</td>\n",
       "      <td>110.9</td>\n",
       "      <td>109.9</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indiana Pacers*</td>\n",
       "      <td>48.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>11.0</td>\n",
       "      <td>105.6</td>\n",
       "      <td>104.2</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Eastern Conference  Wins  Losses  Win-Loss Percentage  Games Behind  \\\n",
       "0      Toronto Raptors*  59.0    23.0                0.720           NaN   \n",
       "1       Boston Celtics*  55.0    27.0                0.671           4.0   \n",
       "2   Philadelphia 76ers*  52.0    30.0                0.634           7.0   \n",
       "3  Cleveland Cavaliers*  50.0    32.0                0.610           9.0   \n",
       "4       Indiana Pacers*  48.0    34.0                0.585          11.0   \n",
       "\n",
       "   Points Per Game  Opponent Points Per Game  Simple Rating System  \n",
       "0            111.7                     103.9                  7.29  \n",
       "1            104.0                     100.4                  3.23  \n",
       "2            109.8                     105.3                  4.30  \n",
       "3            110.9                     109.9                  0.59  \n",
       "4            105.6                     104.2                  1.18  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data,columns=header)\n",
    "def parse_html_table(table_node):\n",
    "    # parse header\n",
    "    header = table_node.thead.find_all('th') # locate each column name using the `th` tag, which entail a string .\n",
    "    # extract the label you want. brevity use .text, for a more informative get teh aria-label attribute\n",
    "    header = [col['aria-label'] for col in header]\n",
    "    # parse rows: the canonical tbody locates the data body.\n",
    "    body = table_node.tbody\n",
    "    # rows are found using the \"tr\" tag\n",
    "    rows = body.find_all('tr')\n",
    "    # each row value has different tags depending on their type (digit or string)\n",
    "    # function to check what tag it is and either convert to float or not. \n",
    "    import numpy as np\n",
    "    def convert_value_type(value_node):\n",
    "        if value_node.name == 'th':\n",
    "            return value_node.text\n",
    "        else: # assume node is td:\n",
    "            try: \n",
    "                return float(value_node.text)\n",
    "            except:\n",
    "                return np.nan # assume there is no value if it fails. \n",
    "    data = []\n",
    "    for row_node in rows:\n",
    "        row = []\n",
    "        for child in row_node.children:\n",
    "            row.append(convert_value_type(child))\n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data,columns=header)\n",
    "    return df\n",
    "df = parse_html_table(table_node)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.2.6:** Now locate all tables from the page, using the `.find_all` method searching for the table tag name. Iterate through the table nodes and apply the function created for parsing html tables. Store each table in a dictionary using the table name as key. The name is found by accessing the id attribute of each table node, using dictionary-style syntax - i.e. `table_node['id']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to Ex. 7.2.2-4 here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table') # locate all table nodes\n",
    "dfs = {}\n",
    "for table_node in tables:\n",
    "    name = table_node['id'] # access the id attribute. \n",
    "    table = parse_html_table(table_node) # apply parse_table function\n",
    "    dfs[name] = table # store table in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.2.7. (extra) :** Compare your results to the pandas implementation. pd.read_html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "87px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
